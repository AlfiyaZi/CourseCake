import requests
from bs4 import BeautifulSoup, NavigableString

from ..scraper import Scraper, InvalidTermId
from .constants import BASE_URL, BASE_HEADERS, DEPARTMENTS, SEARCH_FORM_DATA, CONFIRM_FORM_DATA, TERMS_FORM_DATA






class CalpolyScraper(Scraper):
    def __init__(self, term_id: str = "2020-FALL-1"):
        Scraper.__init__(self, "calpoly", term_id)
        self.session = requests.Session()
        self.session.headers = BASE_HEADERS
        self.term_encoder = self.__init_terms()

        try:
            self.term_code = self.term_encoder[self.term_id]
        except KeyError:
            raise InvalidTermId(self.term_id)



    def __init_terms(self):
        term_encoder = dict()

        initial_response = self.session.get(BASE_URL)
        terms_response = self.session.post(BASE_URL, data = TERMS_FORM_DATA)

        terms_page= BeautifulSoup(terms_response.content, "lxml")
        terms_table = terms_page.find_all("table", id = "PTSRCHRESULTS")[-1]


        for row in terms_table.children:
            if not isinstance(row, NavigableString):
                cells = row.find_all("td")
                if len(cells) > 2:
                    term_info = cells[1].text.strip().upper().split()

                    # Our unique identifier for a term
                    term_id = f"{term_info[2]}-{term_info[0]}-1"

                    # calpoly's unique identifier for a term
                    term_code = cells[0].text.strip()
                    term_encoder[term_id] = term_code

        return term_encoder




    def scrape_classes_page(self, page):
        soup = BeautifulSoup(page.content, "lxml")



    def get_classes(self, testing: bool = False, term_code: str = None) -> dict:
        test_limit = 3

        term = {"SLO_SS_DERIVED_STRM": term_code}


        for i in range(len(DEPARTMENTS)):
            department = DEPARTMENTS[i]
            # each department search needs to start with a get request
            # this allows for a "clean" page, since each page is
            # dynamically generated by AJAX
            first_response = self.session.get(BASE_URL)

            body = SEARCH_FORM_DATA
            body.update({"SSR_CLSRCH_WRK_SUBJECT_SRCH$0": department})

            search_response = self.session.post(BASE_URL, data = body)

            # check if this window is a confirmation page
            if ("SSR_CLSRCH_ENTRY" in search_response.text[:100]):

                # send confirmation to get the actual search response
                search_response = session.post(BASE_URL, data = CONFIRM_FORM_DATA)
                print(f"finished {department}")

            # terminate loop early for tests
            if testing:
                if i + 1 > test_limit:
                    break

        return self.courses
